{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ed40f5a8-916f-4ef1-8fe8-24cf3321dd04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1. Configuration de Key vault sur Azure\n",
    "- Azure Key vault  est un service pour stocker les clés et certficats Azure. \n",
    "- Aprés avoir creer sa clé sur Azure , ajoutez #secrets/createScope à l'URL de votre workspace Databricks. \n",
    "\n",
    "Example: \n",
    "\"https://adb-533378876492000.0.azuredatabricks.net/\" +  \"#secrets/createScope\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3b96d5a6-727b-4f1f-8ab9-a366e939fe75",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2. Récupérer un secret avec dbutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "744c5297-635e-47d8-88ac-005069a7add7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "storage_account_key = dbutils.secrets.get(scope=\"key_adls\", key=\"storage_key\")\n",
    "# Configuration de l'accès au compte de stockage Azure comptestorage0000000001\n",
    "spark.conf.set(\"fs.azure.account.key.comptestorage0000000001.dfs.core.windows.net\", storage_account_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b752978a-9078-447f-af7d-d206d1b05b6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "secret=dbutils.secrets.get(scope=\"key_adls\", key=\"storage_key\")\n",
    "print(secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "94354066-af6c-450e-b164-0200377c7268",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 💡 Astuce : Afficher une redacted value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0eb7563d-9e81-49b4-aeb6-45b0db4f5bac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "clear=\"\"\n",
    "\n",
    "for c in secret:\n",
    "    clear+=c+\" \"\n",
    "print(clear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1f0b1ea8-f464-40f3-96fc-2d74fa7e04c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 🛠️  3. Display un fichier csv situé dans un conteneur abfss \n",
    "### 💡  ABFSS : Azure Blob File System Secure – utilisé pour accéder aux fichiers dans un Data Lake Gen2 avec l'authentification sécurisée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be81c696-5193-4e51-a06f-f19eaf36d226",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": null,
       "filterBlob": "{\"filterGroups\":[{\"enabled\":true,\"filterGroupId\":\"fg_e1cf0e92\",\"op\":\"OR\",\"filters\":[{\"filterId\":\"f_dc58a058\",\"enabled\":true,\"columnId\":\"date_de_tirage\",\"dataType\":\"string\",\"filterType\":\"oneof\"}],\"local\":false,\"updatedAt\":1748341034510}],\"syncTimestamp\":1748341034512}",
       "queryPlanFiltersBlob": "[]",
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#Chemin vers le conteneur Azure \"test\"\n",
    "source_path = \"abfss://test@comptestorage0000000001.dfs.core.windows.net/input/\"\n",
    "#fichier situé dans le conteneur\n",
    "File_name=\"loto_201902__.csv\"\n",
    "\n",
    "FullURL=source_path+File_name\n",
    "\n",
    "df= spark.read.format(\"csv\").option(\"header\", \"true\").option(\"delimiter\", \";\").load(FullURL)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f90a6da0-100d-42c8-95cb-c4d495a637ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 4. 🧪 Cas d’usage:\n",
    "### Filtre sur le Data frame:\n",
    "Nous voudrions selectionner les gagnants du loto ayant les conditions suivantes:\n",
    "\n",
    "- date_de_tirage > 01/01/2019\n",
    "\n",
    "- date_de_forclusion < 01/01/2020\n",
    "\n",
    "- jour_de_tirage == \"SAMEDI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a55d094f-f77a-4da4-be45-522e10d90afe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, to_date, sum\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "# Conversion des dates (format français)\n",
    "df = df.withColumn(\"date_de_tirage\", to_date(col(\"date_de_tirage\"), \"dd/MM/yyyy\")) \\\n",
    "       .withColumn(\"date_de_forclusion\", to_date(col(\"date_de_forclusion\"), \"dd/MM/yyyy\"))\n",
    "\n",
    "df_filtred = df.filter(\n",
    "    (col(\"date_de_tirage\") > \"2019-01-01\") &\n",
    "    (col(\"date_de_forclusion\") < \"2020-01-01\") &\n",
    "    (col(\"jour_de_tirage\").isNotNull()) &\n",
    "    (col(\"jour_de_tirage\").rlike(\"(?i)^samedi\\\\s*$\"))  # insensible à la casse, ignore les espaces\n",
    ")\n",
    "\n",
    "df_filtred = df_filtred.withColumn(\"nombre_de_gagnant_au_rang1\", col(\"nombre_de_gagnant_au_rang1\").cast(IntegerType()))\n",
    "\n",
    "total_gagnants = df_filtred.select(sum(\"nombre_de_gagnant_au_rang1\")).collect()[0][0]\n",
    "\n",
    "print(\"Nombre total de gagnants au rang 1 (tirages du samedi en 2019) :\", total_gagnants)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "836665a8-45cf-460f-82fe-e843c72a346a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 5. 📌 Création d'une vue temporaire dans le catalog Databricks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ed5415f1-36e0-402b-8ccd-34feb19edbc6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Maintenant, nous voudrions creer une vue temporaire (i.e dans le notebook uniquement).\n",
    "\n",
    "Nous suiverons le workflow suivant: \n",
    "1. Lire le CSV\n",
    "2. Nettoyage minimal\n",
    "3. Creer la vue temporaire\n",
    "4. Interroger la vue via SQL \n",
    "5. Sauvegarder le résultat dans une table Delta (dans le catalog Databricks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15bf35c2-3cae-4046-89db-350504240bf4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date, col\n",
    "\n",
    "# 1. Lire le CSV\n",
    "df = (\n",
    "    spark.read.format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"delimiter\", \";\")   \n",
    "    .load(FullURL)\n",
    ")\n",
    "\n",
    "# 2. Nettoyage minimal : convertir les colonnes de date et les gagnants en types corrects\n",
    "df_cleaned = (\n",
    "    df.withColumn(\"date_de_tirage\", to_date(\"date_de_tirage\", \"dd/MM/yyyy\"))\n",
    "      .withColumn(\"date_de_forclusion\", to_date(\"date_de_forclusion\", \"dd/MM/yyyy\"))\n",
    "      .withColumn(\"nombre_de_gagnant_au_rang1\", col(\"nombre_de_gagnant_au_rang1\").cast(\"int\"))\n",
    ")\n",
    "\n",
    "# 3. Créer une vue temporaire (dans le notebook uniquement)\n",
    "df_cleaned.createOrReplaceTempView(\"vue_loto\")\n",
    "\n",
    "# 4. Interroger la vue via SQL (facultatif, par exemple pour vérifier les samedis de 2019)\n",
    "df_result = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        date_de_tirage,\n",
    "        jour_de_tirage,\n",
    "        nombre_de_gagnant_au_rang1\n",
    "    FROM vue_loto\n",
    "    WHERE \n",
    "        date_de_tirage >= '2019-01-01'\n",
    "        AND date_de_forclusion < '2020-01-01'\n",
    "        AND UPPER(TRIM(jour_de_tirage)) = 'SAMEDI'\n",
    "\"\"\")\n",
    "\n",
    "# 5. Sauvegarder le résultat dans une table Delta (dans le catalog Databricks)\n",
    "df_result.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"loto_samedis_2019\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b84f107e-2e6b-4e73-8b63-c5d005d62382",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM loto_samedis_2019 LIMIT 10\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6362119508657303,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "TP n° 5 CSV to Delta table",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
