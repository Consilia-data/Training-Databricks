# Consilia
# ğŸš€ Training_Databricks

**Training_Databricks** est un projet de dÃ©monstration et de formation orientÃ© Data Engineering, construit autour de lâ€™environnement **Databricks**. Il regroupe plusieurs notebooks illustrant les Ã©tapes clÃ©s dâ€™un pipeline de traitement de donnÃ©es dans une architecture **Data Lakehouse** moderne.

---

## ğŸ“Œ Objectifs

- Mettre en pratique lâ€™**ingestion**, la **transformation** et lâ€™**exploitation** de donnÃ©es structurÃ©es et semi-structurÃ©es via **Databricks**.
- Illustrer lâ€™utilisation de **Delta Lake**, des **tables managÃ©es**, des **vues logiques** et des bonnes pratiques de traitement dans un environnement distribuÃ©.
- Poser les bases dâ€™un rÃ©fÃ©rentiel de travail et de formation pour les futurs projets data de lâ€™entreprise.

---

## ğŸ§± Architecture cible

Ce projet sâ€™inscrit dans une architecture **Azure + Databricks**, avec :

- ğŸ“‚ **Azure Data Lake Storage (ADLS Gen2)** : stockage de donnÃ©es brutes
- âš™ï¸ **Databricks (PySpark / SQL)** : traitement, transformation, enrichissement
- ğŸ“ **Delta Lake** : stockage transactionnel avec gestion des mÃ©tadonnÃ©es et historique
- ğŸ“Š **Power BI** *(optionnel)* : visualisation des donnÃ©es issues de la couche Gold

---

## ğŸ“š Contenu des notebooks

| Dossier / Notebook       | Description                                                                 |
|--------------------------|-----------------------------------------------------------------------------|
| `ingestion/`             | Ingestion de fichiers CSV / JSON depuis ADLS ou DBFS                        |
| `bronze_to_silver/`      | Nettoyage, standardisation des schÃ©mas et enrichissement mÃ©tier             |
| `silver_to_gold/`        | AgrÃ©gation, jointures et crÃ©ation de tables analytiques pour exposition     |
| `views/`                 | CrÃ©ation de **vues SQL** sur tables Delta pour faciliter la consommation    |
| `utils/` *(optionnel)*   | Fonctions utilitaires (gestion de schÃ©ma, contrÃ´les, logging)               |

---

## âœ… PrÃ©requis

- Un workspace **Databricks** opÃ©rationnel
- Un cluster Spark configurÃ© (Runtime 11.3+ recommandÃ©)
- Droits dâ€™accÃ¨s Ã  un **Data Lake** ou Ã  **DBFS**
- (Optionnel) IntÃ©gration avec **GitHub** et Unity Catalog

---

## ğŸ›¡ï¸ Bonnes pratiques mises en Å“uvre

- Utilisation des couches **Bronze / Silver / Gold**
- Format **Delta Lake** pour tous les traitements persistÃ©s
- SÃ©paration claire entre traitement, logique mÃ©tier et exposition
- ReproductibilitÃ© et clartÃ© du code (modularitÃ©, commentaires, noms explicites)
- VÃ©rification des schÃ©mas avant fusion de fichiers

---

## ğŸ‘¥ Auteur

Projet dÃ©veloppÃ© par lâ€™Ã©quipe **Consilia Data** â€“ [GitHub: @Consilia-data](https://github.com/Consilia-data)  
ğŸ“« Contact : 
- rboudiba@consilia-data.com 
- zamara@consilia-data.com
- rsaber@consilia-data.com

---

## ğŸ“ Licence

Ce projet est mis Ã  disposition sous licence MIT. Voir le fichier `LICENSE` pour plus dâ€™informations.
