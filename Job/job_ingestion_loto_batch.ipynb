{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a79c7e21-ffea-4053-9b7a-cd8c383f8e04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "job_ingestion_loto\n",
    "\n",
    " 1. CrÃ©er un Pipeline DLT pour ingestion continue (streaming)\n",
    "\n",
    "- ðŸ“ Fichier Python Ã  utiliser comme pipeline : dlt_loto_pipeline.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5b8ab9a3-6a8b-4f4d-8daf-55a63ec5f335",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql.functions import col, to_date, upper\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "\n",
    "# ðŸ“‚ Chemin d'accÃ¨s au fichier CSV dans ADLS\n",
    "file_path = \"abfss://test@comptestorage0000000001.dfs.core.windows.net/input/loto_201902__.csv\"\n",
    "\n",
    "# ðŸ§¾ SchÃ©ma du fichier\n",
    "schema = StructType([\n",
    "    StructField(\"date_de_tirage\", StringType(), True),\n",
    "    StructField(\"date_de_forclusion\", StringType(), True),\n",
    "    StructField(\"jour_de_tirage\", StringType(), True),\n",
    "    StructField(\"gagnant\", StringType(), True)\n",
    "])\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# ðŸ“¥ Lecture du fichier avec schÃ©ma\n",
    "df_loto = (\n",
    "    spark.read\n",
    "    .option(\"header\", True)\n",
    "    .schema(schema)\n",
    "    .csv(file_path)\n",
    ")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# ðŸ§¼ Nettoyage et filtrage selon les conditions demandÃ©es\n",
    "df_filtrÃ© = (\n",
    "    df_loto\n",
    "    .withColumn(\"date_de_tirage\", to_date(\"date_de_tirage\", \"yyyy-MM-dd\"))\n",
    "    .withColumn(\"date_de_forclusion\", to_date(\"date_de_forclusion\", \"yyyy-MM-dd\"))\n",
    "    .filter(col(\"date_de_tirage\") > \"2019-01-01\")\n",
    "    .filter(col(\"date_de_forclusion\") < \"2020-01-01\")\n",
    "    .filter(upper(col(\"jour_de_tirage\")) == \"SAMEDI\")\n",
    ")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# ðŸ‘ï¸â€ðŸ—¨ï¸ Affichage final\n",
    "display(df_filtrÃ©)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "job_ingestion_loto_batch",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
